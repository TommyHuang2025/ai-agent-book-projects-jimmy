# LLM Provider API Keys
# Set the API key for your chosen provider

# Kimi/Moonshot
MOONSHOT_API_KEY=your_kimi_api_key_here

# Doubao
ARK_API_KEY=your_doubao_api_key_here

# OpenAI (required for embeddings)
OPENAI_API_KEY=your_openai_api_key_here

# SiliconFlow
SILICONFLOW_API_KEY=your_siliconflow_api_key_here

# Anthropic (optional, for context generation)
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Configuration Settings
# Default LLM provider (kimi, doubao, openai, siliconflow)
LLM_PROVIDER=kimi

# Optional: Override default model
# LLM_MODEL=kimi-k2-0905-preview

# Temperature for LLM responses
LLM_TEMPERATURE=0.7

# Indexing Configuration
# Number of conversation rounds per chunk
CHUNK_SIZE=20

# Enable contextual retrieval (true/false)
ENABLE_CONTEXTUAL=true

# Embedding model (OpenAI models)
EMBEDDING_MODEL=text-embedding-3-small

# Agent Configuration
# Maximum ReAct iterations
MAX_ITERATIONS=5

# Number of memory chunks to retrieve
SEARCH_TOP_K=10

# Enable reranking (true/false)
ENABLE_RERANKING=true

# Debug and Logging
# Enable debug mode (true/false)
DEBUG=false

# Enable verbose output (true/false)
VERBOSE=true
